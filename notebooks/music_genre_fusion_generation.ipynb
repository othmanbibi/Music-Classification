{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105292f2",
   "metadata": {},
   "source": [
    "# Inteligent Music Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcdc89e",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb632fc",
   "metadata": {},
   "source": [
    "\n",
    "**1. Project Goals**\n",
    "\n",
    "My project is aimed at **AI-based music fusion** and generation using two main generative approaches:\n",
    "\n",
    "1. **Variational Autoencoder (VAE)**\n",
    "\n",
    "   * Used for **interpolation between existing MIDI tracks**.\n",
    "   * Produces smooth transitions between melodies, blending two pieces into a hybrid track.\n",
    "2. **Generative Adversarial Network (GAN)**\n",
    "\n",
    "   * Trained on a large MIDI dataset.\n",
    "   * Generates **completely new tracks** in the style of the training set.\n",
    "   * Can produce novel compositions not directly derived from any input.\n",
    "\n",
    "Additional components:\n",
    "\n",
    "* **Website**: UI for users to explore examples and use the system.\n",
    "* **Web Scraper**: Efficiently downloads MIDI samples from sites.\n",
    "* **Transposer**: Standardizes all MIDI files to the same key, ensuring compatibility when fusing or interpolating.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Three Main Approaches**\n",
    "\n",
    "**A. Interpolation on Existing Music (VAE)**\n",
    "\n",
    "1. Two MIDI tracks are input to a VAE.\n",
    "2. VAE encodes each track into **latent vectors**.\n",
    "3. Latent vectors are **interpolated** (weighted average or smooth blending).\n",
    "4. Decoder outputs a new MIDI track that **blends the musical content** of both tracks.\n",
    "\n",
    "**Use case:**\n",
    "\n",
    "* Fusion of two known songs, genres, or melodies.\n",
    "* Preserves structure and style of original tracks.\n",
    "\n",
    "\n",
    "\n",
    "**B. GAN Generation**\n",
    "\n",
    "1. GAN is trained on a **large MIDI dataset**.\n",
    "2. Once trained, the generator can produce **entirely new MIDI tracks** in the learned style.\n",
    "3. Output tracks can be used as **fresh material** for further processing.\n",
    "\n",
    "**Use case:**\n",
    "\n",
    "* Generating novel music in a specific genre.\n",
    "* Expands creative possibilities beyond existing tracks.\n",
    "\n",
    "\n",
    "**C. GAN + VAE (Hybrid Fusion)**\n",
    "\n",
    "1. GAN generates two new MIDI tracks.\n",
    "2. These tracks are passed through the **VAE interpolation pipeline**.\n",
    "3. Output is a **blended track**, combining both the generative creativity of GAN and the smooth interpolation of VAE.\n",
    "\n",
    "**Use case:**\n",
    "\n",
    "* Creating unique compositions by fusing two GAN-generated tracks.\n",
    "* Produces music that is both novel and coherent.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Supporting Tools**\n",
    "\n",
    "**A. Transposer**\n",
    "\n",
    "* Ensures all tracks are in the **same musical key**.\n",
    "* Important because interpolating tracks in different keys can sound dissonant.\n",
    "\n",
    "**B. Web Scraper**\n",
    "\n",
    "* Collects MIDI samples efficiently from websites.\n",
    "* Enables training GANs or VAE on larger datasets.\n",
    "\n",
    "**C. Website Interface**\n",
    "\n",
    "* Demonstrates examples and allows users to **experiment with music fusion**.\n",
    "* Likely includes:\n",
    "\n",
    "  * Upload interface for MIDI tracks\n",
    "  * Selection of fusion method (VAE interpolation, GAN generation, hybrid)\n",
    "  * Playback of generated music\n",
    "\n",
    "---\n",
    "\n",
    "**4. How the Methods Complement Each Other**\n",
    "\n",
    "| Method            | Strength                                                        | Weakness                                         |\n",
    "| ----------------- | --------------------------------------------------------------- | ------------------------------------------------ |\n",
    "| VAE interpolation | Smooth blending of existing tracks, preserves musical structure | Cannot create completely new content             |\n",
    "| GAN generation    | Generates novel tracks in learned style                         | May produce incoherent or unpolished outputs     |\n",
    "| GAN + VAE hybrid  | Combines novelty with coherence                                 | Computationally heavier, may need careful tuning |\n",
    "\n",
    "* Essentially, **VAE handles smoothness and interpolation**, while **GAN handles creativity and new content generation**.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Summary Workflow Diagram**\n",
    "\n",
    "```\n",
    "Existing MIDI tracks → Transposer → VAE → Interpolated MIDI\n",
    "          │\n",
    "          └─> GAN (trained on dataset) → New MIDI tracks\n",
    "                       │\n",
    "                       └─> VAE → Interpolated GAN MIDI\n",
    "```\n",
    "\n",
    "* This captures all three approaches:\n",
    "\n",
    "  1. Direct VAE interpolation\n",
    "  2. GAN generation\n",
    "  3. Hybrid GAN + VAE interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f9ea9a",
   "metadata": {},
   "source": [
    "**1. Website Goals**\n",
    "\n",
    "The website should allow users to:\n",
    "\n",
    "1. Upload **MIDI or audio files**.\n",
    "2. Generate new music using:\n",
    "\n",
    "   * **VAE interpolation** (blend two tracks)\n",
    "   * **GAN generation** (create new tracks)\n",
    "   * **Hybrid GAN + VAE** (blend two GAN-generated tracks)\n",
    "3. Listen to and download generated music.\n",
    "4. Explore example tracks and demos.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Core Services / Features**\n",
    "\n",
    "Here’s a breakdown of **services** the website should offer:\n",
    "\n",
    "| Service                       | Description                                                             | Implementation Notes                                                                      |\n",
    "| ----------------------------- | ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |\n",
    "| **File Upload**               | Users upload MIDI files (and optionally audio if you add transcription) | Use an HTML file input or drag-and-drop. Backend stores files temporarily for processing. |\n",
    "| **Track Fusion (VAE)**        | Blend two uploaded MIDI tracks                                          | Backend calls MusicVAE to encode, interpolate, decode, and return MIDI.                   |\n",
    "| **Track Generation (GAN)**    | Generate new track in a specific genre                                  | Backend runs GAN inference. Provide parameters like style or seed.                        |\n",
    "| **Hybrid Fusion (GAN + VAE)** | Generate two GAN tracks, then interpolate                               | Combine GAN generation and VAE interpolation pipelines.                                   |\n",
    "| **Playback**                  | Listen to results in browser                                            | Convert MIDI → WAV → stream with `<audio>` HTML element. Use FluidSynth or WebAudio API.  |\n",
    "| **Download**                  | Download generated tracks                                               | Serve as `.mid` or `.wav` files.                                                          |\n",
    "| **Examples / Gallery**        | Showcase pre-generated tracks                                           | Static page or dynamic gallery showing genre fusion examples.                             |\n",
    "| **Transposition (Optional)**  | Normalize key of uploaded tracks                                        | Can be done server-side using MIDI libraries.                                             |\n",
    "\n",
    "---\n",
    "\n",
    "**3. Backend Architecture**\n",
    "\n",
    "The backend handles **all AI processing**, file conversion, and storage. Here’s a suggested setup:\n",
    "\n",
    "**A. Stack**\n",
    "\n",
    "* **Language:** Python (best for Magenta / GAN / VAE)\n",
    "* **Web framework:** Flask, FastAPI, or Django\n",
    "* **AI libraries:** Magenta (MusicVAE), TensorFlow, PyTorch (GAN)\n",
    "* **MIDI/audio tools:** pretty\\_midi, fluidsynth, soundfile\n",
    "\n",
    "**B. API Endpoints**\n",
    "\n",
    "| Endpoint              | Method | Description                                 |\n",
    "| --------------------- | ------ | ------------------------------------------- |\n",
    "| `/upload`             | POST   | Upload MIDI files, returns file IDs         |\n",
    "| `/generate/vae`       | POST   | Interpolate two tracks via VAE              |\n",
    "| `/generate/gan`       | POST   | Generate a new track via GAN                |\n",
    "| `/generate/hybrid`    | POST   | Generate GAN tracks and interpolate via VAE |\n",
    "| `/download/<file_id>` | GET    | Download generated track                    |\n",
    "| `/play/<file_id>`     | GET    | Stream generated audio                      |\n",
    "\n",
    "\n",
    "**C. Processing Flow**\n",
    "\n",
    "1. User uploads files → backend stores them.\n",
    "2. For VAE:\n",
    "\n",
    "   * Encode files → interpolate → decode → MIDI.\n",
    "3. For GAN:\n",
    "\n",
    "   * Generate new MIDI → optionally interpolate via VAE.\n",
    "4. Convert MIDI → WAV for playback.\n",
    "5. Return downloadable file URLs and streaming links.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Frontend Layout**\n",
    "\n",
    "**A. Pages / Components**\n",
    "\n",
    "1. **Home / Landing Page**\n",
    "\n",
    "   * Introduction and examples of AI-generated music.\n",
    "2. **Upload / Fusion Page**\n",
    "\n",
    "   * File upload inputs (2 tracks for VAE)\n",
    "   * Buttons: VAE, GAN, Hybrid\n",
    "   * Genre/style selection for GAN\n",
    "   * Audio player to preview generated track\n",
    "   * Download button\n",
    "3. **Gallery / Examples**\n",
    "\n",
    "   * Pre-generated tracks with descriptions\n",
    "4. **About / Documentation**\n",
    "\n",
    "   * How the system works (VAE, GAN, hybrid)\n",
    "\n",
    "**B. Interactivity**\n",
    "\n",
    "* Use AJAX / fetch API to call backend without reloading page.\n",
    "* Display **progress/loading bar** for generation (AI models can take time).\n",
    "* Show **waveform or MIDI piano roll preview** (optional, for visual appeal).\n",
    "\n",
    "---\n",
    "\n",
    "**5. Optional Advanced Features**\n",
    "\n",
    "1. **User Accounts**\n",
    "\n",
    "   * Save favorite generated tracks.\n",
    "   * Track history of generated music.\n",
    "\n",
    "2. **Genre Customization**\n",
    "\n",
    "   * Allow user to pick genres, BPM, key, or mood.\n",
    "\n",
    "3. **Audio Upload**\n",
    "\n",
    "   * If you implement audio → MIDI transcription, allow vocal or instrument tracks.\n",
    "\n",
    "4. **Batch Processing**\n",
    "\n",
    "   * Let users generate multiple fused tracks at once.\n",
    "\n",
    "---\n",
    "\n",
    "**6. Tech Stack Summary**\n",
    "\n",
    "| Layer      | Technology                                      |\n",
    "| ---------- | ----------------------------------------------- |\n",
    "| Frontend   | HTML, CSS, JS, React or Vue (optional)          |\n",
    "| Backend    | Python + Flask/FastAPI                          |\n",
    "| AI Models  | MusicVAE (Magenta), GAN (PyTorch or TensorFlow) |\n",
    "| MIDI/Audio | pretty\\_midi, fluidsynth, soundfile             |\n",
    "| Storage    | Local filesystem or cloud (S3) for MIDI/WAV     |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4815903",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f996484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113f76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Music_ML_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
